<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.147.3"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Implicit degree bias in the link prediction task
</title><link rel="shortcut icon" type=image/x-icon href=/><link rel=stylesheet href=/css/main.51652302d3a998bf7887aed5c2cf89141bbebdf45a2c8f87b0717a3cf4f51c4e53c694c328fb1de78c3a625a1c01f80745bf1f2f42c040647a245cbbb6c2d1d7.css integrity="sha512-UWUjAtOpmL94h67Vws+JFBu+vfRaLI+HsHF6PPT1HE5TxpTDKPsd54w6YlocAfgHRb8fL0LAQGR6JFy7tsLR1w=="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css integrity=sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js integrity=sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body a=light><main class=page-content aria-label=Content><div class=w><header><h1>Implicit degree bias in the link prediction task</h1></header><style>.btn{display:flex;align-items:center;justify-content:center;width:180px;height:44px;padding:0 12px;margin:0;font-size:.95rem;font-weight:700;text-align:center;background-color:#444;color:#fff;border-radius:16px;text-decoration:none;box-sizing:border-box;transition:background .2s}.btn:hover{background-color:#222}.img-center{display:block;margin-left:auto;margin-right:auto}.btn .icon{margin-right:10px;font-size:1.2rem;display:flex;align-items:center}.button-row{display:flex;gap:32px;justify-content:center;margin:32px 0;flex-wrap:wrap}.team-section{margin:48px 0;text-align:center}.team-grid{display:grid;grid-template-columns:repeat(3,1fr);gap:40px 64px;justify-items:center;margin-top:24px}.team-member{display:flex;flex-direction:column;align-items:center;width:180px}.team-member img{width:120px;height:120px;object-fit:cover;border-radius:50%;border:2px solid #444;margin-bottom:12px}.team-member .name{font-weight:700;font-size:1.15em;margin-bottom:4px}.team-member .affiliation{font-size:1.05em;color:#888;font-family:georgia,serif;margin-bottom:2px;white-space:pre-line}.author-byline{display:flex;align-items:center;gap:16px;font-family:Arial,sans-serif;justify-content:flex-end}.author-avatar{width:40px;height:40px;border-radius:50%;object-fit:cover;margin-right:0}.author-name{font-weight:500;font-size:1.1em}.follow-btn{padding:6px 18px;border:1.5px solid #222;border-radius:24px;background:#fff;font-weight:500;cursor:pointer;transition:background .2s,color .2s}.follow-btn:hover{background:#222;color:#fff}.meta{color:#888;font-size:.98em;margin-left:8px}</style><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css><div class=button-row><a class=btn href=paper.pdf target=_blank style=color:#fff><span class=icon><i class="fas fa-file-pdf"></i></span>
Paper (TBD)
</a><a class=btn href=https://arxiv.org/abs/2405.14985 target=_blank style=color:#fff><span class=icon><i class="fas fa-file-pdf"></i></span>
Preprint
</a><a class=btn href=https://github.com/skojaku/degree-corrected-link-prediction-benchmark target=_blank style=color:#fff><span class=icon><i class="fab fa-github"></i></span>
GitHub</a></div><div class=author-byline><img class=author-avatar src=assets/headshots/sadamori.jpeg alt="Sadamori Kojaku"><p><span class=author-name>Sadamori Kojaku</span></p><p>üìß <a href=mailto:skojaku@binghamton.edu>skojaku@binghamton.edu</a></p></div><h2 id=summary>Summary</h2><p>Link prediction benchmarks are widely used to evaluate models for recommendations and discovery. However, a subtle design flaw&mdash;uniform sampling of edges&mdash;introduces a <strong>degree bias</strong> that inflates performance scores for trivial heuristics. In a benchmark of 27 models across 95 real-world networks, we find that many models achieve excessively high benchmark performance by merely identifying high-degree nodes, not learning structural patterns. This post explains how this happens and outlines steps to fix the evaluation pipeline.</p><h3 id=-click-here-for-frequently-asked-questions->‚ñ∂Ô∏è <a href=#questions-and-answers>Click here for frequently asked questions üôã</a></h3><h2 id=benchmark-scores-can-be-misleading>Benchmark scores can be misleading</h2><h3 id=disconnect-between-benchmark-and-real-world-performance>Disconnect between benchmark and real-world performance</h3><p>Let us showcase the disconnect between benchmark scores and real-world effectiveness using 27 models across 95 real-world networks. We compared standard benchmark performance with a practical retrieval task (recommending the top K connections for a node, similar to social media friend suggestions). We found that over 60% of models that ranked at the top in standard benchmarks failed to be top performers in the retrieval task for about 70% of networks. This shows that high benchmark scores do not always mean good real-world performance.</p><p><img src=assets/figs/rbo-distribution-3.png alt></p><h3 id=benchmark-ranks-a-crude-model-as-the-best>Benchmark ranks a crude model as the best</h3><p>Let us showcase the issue by using <strong>the preferential attachment method</strong>, which predicts edges between two nodes \(i\) and \(j\) based on score
$$
\text{score}(i,j) = k_i k_j
$$
where \(k_i\) is the degree of node \(i\).
This is a crude prediction: it predicts edges solely based on node degrees, ignoring other highly useful network information (e.g., distance, common neighbors, etc.).</p><p>Despite its simplicity, the preferential attachment method performs surprisingly well on the benchmarküëá:</p><p>(bold \(\sim\) benchmark performance)</p><ul><li><strong>0.94/1.00</strong> on a all-science citation network</li><li><strong>0.91/1.00</strong> on the US patent citation network</li><li><strong>0.93/1.00</strong> on a protein interaction network</li><li><strong>0.99/1.00</strong> on a drug interaction network</li></ul><p>Think about the citation network, for example.
The high performance of preferential attachment means that the model can predict citations based solely on a paper&rsquo;s popularity (references and citations count), completely ignoring content relevance. This contradicts our understanding of how researchers actually select citations &mdash; based on relevance to their work, not just solely on popularity.</p><p>The preferential attachment method even outperforms the-state-of-the-art models like BUDDY for highly degree-heterogeneous networks (right). This occurs despite such advanced models incorporating detailed network structures such as neighborhood information and node distances in addition to degree information. It turns out that this is not because of the superiority of the preferential attachment method, but because it leverages a shortcut, as we will show in the next section.</p><div><marimo-iframe data-height=600px data-width=100% data-show-code=false><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:red>import</span> pandas <span style=color:red>as</span> pd
</span></span><span style=display:flex><span><span style=color:red>import</span> marimo <span style=color:red>as</span> mo
</span></span><span style=display:flex><span><span style=color:red>import</span> numpy <span style=color:red>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plot_data = pd.read_csv(<span style=color:#87ceeb>&#34;https://raw.githubusercontent.com/skojaku/degree-corrected-link-prediction-benchmark/refs/heads/main/docs/static/assets/aucroc-agg.csv&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>focal_method_dict = {
</span></span><span style=display:flex><span>    <span style=color:#87ceeb>&#34;preferentialAttachment&#34;</span>: <span style=color:#87ceeb>&#34;Preferential Attachment&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#87ceeb>&#34;Buddy&#34;</span>: <span style=color:#87ceeb>&#34;BUDDY&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#0f0>#&#34;fineTunedGAT&#34;: &#34;GAT&#34;,</span>
</span></span><span style=display:flex><span>    <span style=color:#0f0>#&#34;fineTunedGraphSAGE&#34;: &#34;GraphSAGE&#34;,</span>
</span></span><span style=display:flex><span>    <span style=color:#0f0>#&#34;node2vec&#34;: &#34;node2vec&#34;,</span>
</span></span><span style=display:flex><span>    <span style=color:#0f0>#&#34;resourceAllocation&#34;: &#34;Resource Allocation&#34;,</span>
</span></span><span style=display:flex><span>    <span style=color:#0f0>#&#34;localPathIndex&#34;: &#34;Local Path Index&#34;,</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plot_data[<span style=color:#87ceeb>&#34;model&#34;</span>] = plot_data[<span style=color:#87ceeb>&#34;model&#34;</span>].map(
</span></span><span style=display:flex><span>    <span style=color:red>lambda</span> x: focal_method_dict[x] <span style=color:red>if</span> x in focal_method_dict <span style=color:red>else</span> x
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>method_button = mo.ui.radio(
</span></span><span style=display:flex><span>    focal_method_dict.values(),
</span></span><span style=display:flex><span>    value=<span style=color:#87ceeb>&#34;Preferential Attachment&#34;</span>,
</span></span><span style=display:flex><span>    inline=<span style=color:red>True</span>,
</span></span><span style=display:flex><span>    label=<span style=color:#87ceeb>&#34;ü§ñ **Link prediction method**&#34;</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#0f0>#sampling_method_dict = {</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#    &#34;Standard (No degree correction)&#34;: &#34;uniform&#34;,</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#    #&#34;Proposed (Degree correction)&#34;: &#34;degreeBiased&#34;,</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#    #&#34;HearT&#34;: &#34;heart&#34;</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#}</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#sampling_button = mo.ui.radio(</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#    sampling_method_dict.keys(),</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#    value=&#34;Standard (No degree correction)&#34;,</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#    inline=True,</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#    label=&#34;üéØ **Benchmark type**&#34;,</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#)</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#mo.vstack([method_button, sampling_button])</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#method_button</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:red>import</span> altair <span style=color:red>as</span> alt
</span></span><span style=display:flex><span><span style=color:#0f0># Assuming plot_data is your original dataframe</span>
</span></span><span style=display:flex><span><span style=color:#0f0># Prepare the data similar to the original code</span>
</span></span><span style=display:flex><span><span style=color:#0f0>#focal_sampling_method = sampling_method_dict[sampling_button.value]</span>
</span></span><span style=display:flex><span>df = plot_data.query(<span style=color:#87ceeb>&#34;negativeEdgeSampler == &#39;uniform&#39;&#34;</span>).copy()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0f0># Create a new column to identify both focal methods</span>
</span></span><span style=display:flex><span>df[<span style=color:#87ceeb>&#34;methodType&#34;</span>] = <span style=color:#87ceeb>&#34;Other&#34;</span>
</span></span><span style=display:flex><span>df.loc[df[<span style=color:#87ceeb>&#34;model&#34;</span>] == <span style=color:#87ceeb>&#34;Preferential Attachment&#34;</span>, <span style=color:#87ceeb>&#34;methodType&#34;</span>] = <span style=color:#87ceeb>&#34;Preferential Attachment&#34;</span>
</span></span><span style=display:flex><span>df.loc[df[<span style=color:#87ceeb>&#34;model&#34;</span>] == <span style=color:#87ceeb>&#34;BUDDY&#34;</span>, <span style=color:#87ceeb>&#34;methodType&#34;</span>] = <span style=color:#87ceeb>&#34;BUDDY&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df = df.sort_values(<span style=color:#87ceeb>&#34;lognorm_sigma&#34;</span>)
</span></span><span style=display:flex><span>df[<span style=color:#87ceeb>&#34;data_code&#34;</span>] = np.arange(df.shape[<span style=color:#f60>0</span>])
</span></span><span style=display:flex><span>df[<span style=color:#87ceeb>&#34;data_code&#34;</span>] = <span style=color:#f60>100</span> * df[<span style=color:#87ceeb>&#34;data_code&#34;</span>] / df[<span style=color:#87ceeb>&#34;data_code&#34;</span>].nunique()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0f0># Create tooltip with dataname and model name</span>
</span></span><span style=display:flex><span>tooltip = [
</span></span><span style=display:flex><span>    alt.Tooltip(<span style=color:#87ceeb>&#34;data:N&#34;</span>, title=<span style=color:#87ceeb>&#34;Dataset&#34;</span>),
</span></span><span style=display:flex><span>    alt.Tooltip(<span style=color:#87ceeb>&#34;model:N&#34;</span>, title=<span style=color:#87ceeb>&#34;Method&#34;</span>),
</span></span><span style=display:flex><span>    alt.Tooltip(<span style=color:#87ceeb>&#34;score:Q&#34;</span>, title=<span style=color:#87ceeb>&#34;AUC-ROC&#34;</span>, format=<span style=color:#87ceeb>&#34;.3f&#34;</span>),
</span></span><span style=display:flex><span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0f0># Common x and y axis definitions</span>
</span></span><span style=display:flex><span>x_axis = alt.X(
</span></span><span style=display:flex><span>    <span style=color:#87ceeb>&#34;data_code:Q&#34;</span>, title=<span style=color:#87ceeb>&#34;Networks (ordered by degree heterogeneity)&#34;</span>, scale=alt.Scale(domain=[-<span style=color:#f60>1</span>, <span style=color:#f60>101</span>])
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>y_axis = alt.Y(<span style=color:#87ceeb>&#34;score:Q&#34;</span>, title=<span style=color:#87ceeb>&#34;AUC-ROC&#34;</span>, scale=alt.Scale(domain=[<span style=color:#f60>0.2</span>, <span style=color:#f60>1.01</span>]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0f0># Create a color scale for method types</span>
</span></span><span style=display:flex><span>color_scale = alt.Scale(
</span></span><span style=display:flex><span>    domain=[<span style=color:#87ceeb>&#34;Preferential Attachment&#34;</span>, <span style=color:#87ceeb>&#34;BUDDY&#34;</span>, <span style=color:#87ceeb>&#34;Other&#34;</span>],
</span></span><span style=display:flex><span>    range=[<span style=color:#87ceeb>&#34;#FF7F0E&#34;</span>, <span style=color:#87ceeb>&#34;#27344d&#34;</span>, <span style=color:#87ceeb>&#34;#d3d3d3&#34;</span>]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0f0># Base chart with color encoding for legend</span>
</span></span><span style=display:flex><span>base = alt.Chart(df).encode(
</span></span><span style=display:flex><span>    x=x_axis,
</span></span><span style=display:flex><span>    y=y_axis,
</span></span><span style=display:flex><span>    color=alt.Color(<span style=color:#87ceeb>&#34;methodType:N&#34;</span>, scale=color_scale, legend=alt.Legend(
</span></span><span style=display:flex><span>        orient=<span style=color:#87ceeb>&#34;top&#34;</span>,
</span></span><span style=display:flex><span>        title=<span style=color:#87ceeb>&#34;Method Types&#34;</span>,
</span></span><span style=display:flex><span>        titleFontSize=<span style=color:#f60>14</span>,
</span></span><span style=display:flex><span>        labelFontSize=<span style=color:#f60>12</span>,
</span></span><span style=display:flex><span>        titleAlign=<span style=color:#87ceeb>&#34;center&#34;</span>,
</span></span><span style=display:flex><span>        titleAnchor=<span style=color:#87ceeb>&#34;middle&#34;</span>,
</span></span><span style=display:flex><span>        direction=<span style=color:#87ceeb>&#34;horizontal&#34;</span>,
</span></span><span style=display:flex><span>        legendX=<span style=color:#f60>400</span>,
</span></span><span style=display:flex><span>    )),
</span></span><span style=display:flex><span>    tooltip=tooltip
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0f0># For other methods (background points)</span>
</span></span><span style=display:flex><span>other_points = base.transform_filter(
</span></span><span style=display:flex><span>    alt.datum.methodType == <span style=color:#87ceeb>&#34;Other&#34;</span>
</span></span><span style=display:flex><span>).mark_circle(size=<span style=color:#f60>40</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0f0># For BUDDY points - using square shape</span>
</span></span><span style=display:flex><span>buddy_points = base.transform_filter(
</span></span><span style=display:flex><span>    alt.datum.methodType == <span style=color:#87ceeb>&#34;BUDDY&#34;</span>
</span></span><span style=display:flex><span>).mark_circle(size=<span style=color:#f60>50</span>, stroke=<span style=color:#87ceeb>&#34;black&#34;</span>, strokeWidth=<span style=color:#f60>0.4</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0f0># For Preferential Attachment points</span>
</span></span><span style=display:flex><span>pa_points = base.transform_filter(
</span></span><span style=display:flex><span>    alt.datum.methodType == <span style=color:#87ceeb>&#34;Preferential Attachment&#34;</span>
</span></span><span style=display:flex><span>).mark_circle(size=<span style=color:#f60>100</span>, stroke=<span style=color:#87ceeb>&#34;black&#34;</span>, strokeWidth=<span style=color:#f60>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0f0># Layer the charts</span>
</span></span><span style=display:flex><span>chart = (
</span></span><span style=display:flex><span>    (other_points + buddy_points + pa_points)
</span></span><span style=display:flex><span>    .properties(width=<span style=color:#f60>400</span>, height=<span style=color:#f60>400</span>)
</span></span><span style=display:flex><span>    .configure_axis(labelFontSize=<span style=color:#f60>16</span>, titleFontSize=<span style=color:#f60>16</span>)
</span></span><span style=display:flex><span>    .configure_view(strokeWidth=<span style=color:#f60>0</span>)
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0f0># Display the chart</span>
</span></span><span style=display:flex><span>chart
</span></span></code></pre></div></marimo-iframe></div><script src=https://cdn.jsdelivr.net/npm/@marimo-team/marimo-snippets@1></script><h2 id=implicit-degree-bias>Implicit degree bias</h2><h3 id=how-the-benchmark-works>How the benchmark works</h3><p>Standard benchmarks for testing link prediction algorithms follow a simple process: take a complete network, randomly remove some edges to create a test set, and train models on the remaining network.
The link prediction model then scores both the held-out edges and randomly sampled non-existent edges.</p><p><img src=assets/figs/random-edge-removal.png alt></p><p>Performance is measured using AUC-ROC, which shows how well the model distinguishes between real missing edges and random non-edges. A higher score means the model is better at ranking actual connections above non-connections.</p><p><img src=assets/figs/aur-roc-schematics.png alt></p><h3 id=a-mismatch>A mismatch</h3><p>The issue of the benchmark stems from <em>sampling</em> of the connected and non-connected node pairs. The connected node pairs are sampled uniformly at random <strong>from edges</strong>. On the other hand, the non-connected node pairs are sampled uniformly at random from <strong>nodes</strong>. Since the high-degree nodes appear more frequently in the edge set, they tend to be sampled more frequently as connected node pairs.</p><p><img src=assets/figs/edge-sampling.png alt></p><p>This creates a mismatch between the positive and negative edges in terms of the node degrees.</p><img src=assets/figs/degree-distribution.png width=50%><p>This mismatch makes the degree-based heuristics work so well: we can distinguish easily by just looking at the degree of the nodes. We call this phenomenon the <strong>degree bias</strong> of the benchmark. This bias excessively inflates the performance of the degree-based heuristics like the preferential attachment method, more than what they would achieve in real-world tasks.</p><h3 id=a-remedy>A remedy</h3><p><img src=assets/figs/idea.png alt></p><p>Think of link prediction benchmarks like clinical trials. In a proper clinical trial, we wouldn&rsquo;t compare patients with a disease (treatment group) to random people (control group) - we&rsquo;d compare them to other patients with the same disease. Similarly, in link prediction, we shouldn&rsquo;t compare positive edges (treatment group) to randomly sampled negative edges (control group). This leads to inaccurate effectiveness of a link prediction model (drug).
Rather, we should sample negative edges with the same degree distribution as the positive edges.</p><p>To this end, we propose the <strong>degree-corrected benchmark</strong>, which samples negative edges that have the same degree distribution as the positive edges. We do this by creating a list of node set with duplicates proportional to the node degrees (i.e., node with degree \(k\) appears \(k\) times in the list). Then we sample negative edges by uniformly sampling two nodes from this list. This way, the negative edges have the same degree distribution as the positive edges.</p><p><img src=assets/figs/biased-negative-sampling.png alt></p><h2 id=results-improving-the-alignment-between-benchmarks-and-real-world-tasks>Results: Improving the alignment between benchmarks and real-world tasks</h2><p>The degree-corrected benchmark improves the alignment between benchmarks and real-world tasks, as is evidenced by more networks with higher RBO scores than the standard benchmark. Namely, the top-performing models in the degree-corrected benchmark are more likely to be the top-performing models in the real-world tasks.</p><p><img src=assets/figs/rbo-distribution-all.png alt></p><h2 id=improving-representation-learning-of-networks>Improving representation-learning of networks</h2><p>The link prediction benchmark is often used as a unsupervised training objective for representation-learning of networks.
We test the utility of the degree-corrected benchmark as a training objective by training graph neural networks (GNNs).
As a quality metric of the learned representations, we focus on whether the embeddings learned by the GNNs encode community structure of networks, as communities are fundamental structures that inform many tasks, including link prediction, node classification, dynamics, and more.
We found that when correcting the degree-bias, the community detection accuracy increases for all the GNNs tested. For more details, please refer to our paper.</p><p><img src=assets/figs/community-detection.png alt></p><hr><h2 id=questions-and-answers>Questions and Answers</h2><p><strong>Q: Does the degree-corrected benchmark remove all predictive power of node degree?</strong></p><p>A: No. If node degree is genuinely predictive of edge formation in the real network (e.g., in rich-club or preferential attachment graphs), degree-based methods will still perform well under the degree-corrected benchmark. The correction only removes the artificial bias introduced by the sampling procedure, not the true signal present in the data. (See biokg_drug discussed in the paper.)</p><p><strong>Q: Does the degree-corrected benchmark introduce new biases, for example against low-degree nodes?</strong></p><p>A: No, the degree-corrected benchmark does not introduce unfair bias against low-degree nodes. In fact, it restores balance to the types of comparisons made between positive and negative edges. In link prediction evaluation, the model&rsquo;s performance is determined by how well it distinguishes positive from negative edges, and these comparisons can be grouped into four types: (1) high-degree positive vs. high-degree negative, (2) high-degree positive vs. low-degree negative, (3) low-degree positive vs. high-degree negative, and (4) low-degree positive vs. low-degree negative.</p><p>In the standard benchmark, there is a strong imbalance: most comparisons are between high-degree positive edges and low-degree negative edges. In degree-heterogeneous networks, over 70% of the AUC-ROC score comes from these &rsquo;easy&rsquo; cases, where degree alone is a strong discriminator. This means the benchmark over-represents situations where high-degree nodes are positives and low-degree nodes are negatives, making it unfairly easy for degree-based methods and not representative of all node types.</p><p>The degree-corrected benchmark, by matching the degree distributions of positive and negative edges, achieves near-perfect parity among all four types of comparisons. This ensures that the model is evaluated fairly across the full spectrum of node degrees, including low-degree nodes. Empirical results show that models trained and evaluated with degree-corrected sampling perform better on tasks that depend on all nodes, not just high-degree ones. (See Supplementary Information Section 3.2 and &ldquo;Improving representation-learning of networks&rdquo; above.)</p><p><strong>Q: How does this benchmark relate to other biases, like distance bias?</strong></p><p>A: Degree bias is more fundamental than distance bias, because node degree influences many other structural properties, including shortest path distances. Our results show that correcting for degree bias also reduces distance bias, but the reverse is not necessarily true. Benchmarks that only address distance bias may still be vulnerable to degree-based shortcuts. (See Discussion and comparison with HeaRT benchmark in the paper.)</p><p><strong>Q: Is the issue limited to small networks?</strong></p><p>A: No. The degree bias is present in any non-regular network, regardless of the size. We have observed that the degree bias tends to be more severe for larger networks, as the degree-heterogeneity tends to be higher for larger networks (See the results for OGB and large-scale network experiments.)</p><p><strong>Q: Why not just use ranking-based metrics like Hits@K or MRR?</strong></p><p>A: The degree bias arises in the benchmark data, which is a problem independent of the choice of evaluation metrics. Indeed, perhaps some metrics are less sensitive to the degree bias, but they can be still affected by it.
In fact, we have observed qualitatively similar results for Hits@K and MRR as an alternative to AUC-ROC, i.e., degree-based methods still perform well on these metrics when the degree distribution is heterogeneous (See Supplementary Information.)</p><p><strong>Q: How does this work relate to OGB and other recent benchmarks?</strong></p><p>A: Our analysis shows that degree bias is present in many popular benchmarks, including those in the Open Graph Benchmark (OGB) suite. The degree-corrected benchmark can be used to improve the fairness and reliability of these evaluations. (See OGB graphs and Discussion section.)</p><p><strong>Q: Why do we bother with benchmarks? Why not just use retrieval tasks?</strong></p><p>A: Link prediction benchmarks offer a more efficient evaluation method than retrieval tasks. While retrieval tasks require searching across all network nodes‚Äîcomputationally expensive for large networks‚Äîbenchmarks use pre-sampled positive and negative edges for classification, making model training much faster. In practice, real-world retrieval systems typically use a two-step approach: first, a computationally efficient retriever model (often trained on link prediction benchmarks) generates candidate nodes, then a more sophisticated model ranks these candidates. Therefore, even for retrieval applications, benchmarks remain essential to the training and evaluation pipeline.</p><hr><h2 id=contact>Contact</h2><ul><li>üìß <a href=mailto:skojaku@binghamton.edu>skojaku@binghamton.edu</a></li><li>üß† <a href=https://skojaku.github.io>skojaku.github.io</a></li></ul><hr><div class=team-section><h2>Team</h2><div class=team-grid><div class=team-member><img src=assets/headshots/rachith.png alt="Rachith Aiyappa">
<a href=https://rachithaiyappa.github.io/ target=_blank><div class=name>Rachith Aiyappa</div></a></div><div class=team-member><img src=assets/headshots/vision.png alt="Xin (Vision) Wang">
<a href=https://xin-wang-kr.github.io/ target=_blank><div class=name>Xin (Vision) Wang</div></a></div><div class=team-member><img src=assets/headshots/mj.png alt="Munjung Kim">
<a href=https://munjungkim.github.io/ target=_blank><div class=name>Munjung Kim</div></a></div><div class=team-member><img src=assets/headshots/ozgur.png alt="Ozgur Can Seckin">
<a href=https://www.ozgurcanseckin.com/ target=_blank><div class=name>Ozgur Can Seckin</div></a></div><div class=team-member><img src=assets/headshots/jisung.png alt="Jisung Yoon">
<a href=https://jisungyoon.github.io/ target=_blank><div class=name>Jisung Yoon</div></a></div><div class=team-member><img src=assets/headshots/yy.png alt="Yong-Yeol Ahn">
<a href=https://yongyeol.com/ target=_blank><div class=name>Yong-Yeol Ahn</div></a></div><div class=team-member><img src=assets/headshots/sadamori.jpeg alt="Sadamori Kojaku">
<a href=https://skojaku.github.io/ target=_blank><div class=name>Sadamori Kojaku</div></a></div></div></div><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js integrity=sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6 crossorigin=anonymous></script><footer class=site-footer><p>&copy; 2025 Implicit degree bias in the link prediction task</p></footer></div></main></body></html>